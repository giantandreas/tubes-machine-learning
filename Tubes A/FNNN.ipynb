{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"font-weigt:bold;\">TUGAS BESAR A MACHINE LEARNING</h2>\n",
    "\n",
    "- Arjuna Marcelino - 13519021\n",
    "- Sharon Bernadetha Marbun - 13519092\n",
    "- Epata Tuah - 13519120\n",
    "- Giant Andreas Tambunan - 13519127"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membaca Data dan Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membaca data\n",
    "import csv\n",
    "\n",
    "def readData():\n",
    "    data = []\n",
    "    target_class = []\n",
    "    dataFile = open('data.csv', \"r\")\n",
    "    reader = csv.DictReader(dataFile)\n",
    "    for row in reader:\n",
    "        data.append([int(row[\"x1\"]), int(row[\"x2\"])])\n",
    "        target_class.append(int(row[\"f\"]))\n",
    "    \n",
    "    return data, target_class\n",
    "\n",
    "\n",
    "# Membaca Model\n",
    "# filename ex: modelsigmoid.txt \n",
    "def readModel(filename):\n",
    "    file = open(filename, \"r\")\n",
    "    lines = file.readlines()\n",
    "\n",
    "    # init array\n",
    "    activation = []\n",
    "    weigth = []\n",
    "    bias = []\n",
    "\n",
    "    num_atr = int(lines[0])\n",
    "    i = 1\n",
    "    while i < len(lines):\n",
    "        splitline = lines[i].strip(\"\\n\").split(\" \")\n",
    "        # baris yang mengandung fungsi aktivasi\n",
    "        if((\"sigmoid\" in splitline) or (\"relu\" in splitline) or (\"linear\" in splitline) or \"softmax\" in splitline):\n",
    "            activation.append(splitline[1])\n",
    "\n",
    "            i +=1\n",
    "            splitline = lines[i].strip(\"\\n\").split(\" \")\n",
    "            bias.append(list(map(int, splitline)))\n",
    "\n",
    "            i+=1\n",
    "        else:\n",
    "            w = []\n",
    "            for num in range(num_atr):\n",
    "                splitline = lines[i].strip(\"\\n\").split(\" \")\n",
    "                w.append(list(map(int, splitline)))\n",
    "                i +=1\n",
    "\n",
    "            weigth.append(w)\n",
    "\n",
    "    return bias, weigth, activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi Aktivasi\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def linear(x, kwargs=None):\n",
    "    return x\n",
    "\n",
    "def sigmoid(x):\n",
    "    value = float(1 / (1 + math.exp(x * -1)))\n",
    "    threshold = 0.1\n",
    "    if value < threshold:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def relu(x):\n",
    "    alpha = 0.0\n",
    "    max_value = 1.0\n",
    "    threshold = 0.0\n",
    "    if x < threshold:\n",
    "        if x > x*alpha:\n",
    "            return x\n",
    "        else:\n",
    "            return x*alpha\n",
    "    else:\n",
    "        return min(x, max_value)\n",
    "\n",
    "def softmax(arr):\n",
    "    arr_exp = np.exp(arr)\n",
    "    return arr_exp / arr_exp.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Class and Layer Class\n",
    "#### Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self,bias:list[int], weight:list[list[int]], activation:str):\n",
    "        self.weight = weight\n",
    "        self.bias = bias\n",
    "        self.activation = activation\n",
    "\n",
    "    \n",
    "    def get_sigma(self, input:list[int]) -> list[int]:\n",
    "        if(len(self.weight) == len(bias)):\n",
    "            result = []\n",
    "            for i in range(len(self.bias)):\n",
    "                res = 1*self.bias[i]\n",
    "                for j in range(len(input)):\n",
    "                    res = res + input[j]*self.weight[j][i]\n",
    "                \n",
    "                result.append(res)\n",
    "            \n",
    "            return result\n",
    "\n",
    "    def get_result(self, input:list[int]):\n",
    "        sigma = self.get_sigma(input)\n",
    "        result = []\n",
    "        for i in range(len(sigma)):\n",
    "            result.append(self.activate_function(sigma[i]))\n",
    "        return result\n",
    "    \n",
    "    def activate_function(self, x):\n",
    "        if(self.activation == \"linear\"):\n",
    "            return linear(x)\n",
    "        elif(self.activation == \"sigmoid\"):\n",
    "            return sigmoid(x)\n",
    "        elif(self.activation == \"relu\"):\n",
    "            return relu(x)\n",
    "        elif(self.activation == \"softmax\"):\n",
    "            return softmax(x)\n",
    "\n",
    "    def getDiGraph(self, index, max):\n",
    "        # untuk visualisasi Digraph\n",
    "        arr = []\n",
    "\n",
    "        # bias\n",
    "        i = 1\n",
    "        for bs in self.bias:\n",
    "            a = f'b{index}'\n",
    "            b = f'h{index+1}_{i}'\n",
    "            if(index+1 == max):\n",
    "                b = f'y'\n",
    "            arr.append([a, b, bs])\n",
    "            i += 1\n",
    "        \n",
    "        # weight \n",
    "        i = 1\n",
    "        for x in self.weight:\n",
    "            j = 1\n",
    "            for w in x:\n",
    "                a = f'x{index}_{i}'\n",
    "                if(index>0):\n",
    "                    a = f'h{index}_{i}'\n",
    "                \n",
    "                b = f'h{index+1}_{j}'\n",
    "                if(index+1 == max):\n",
    "                    b = f'y'\n",
    "                arr.append([a, b, w])\n",
    "                \n",
    "                j += 1\n",
    "            i += 1\n",
    "\n",
    "        return arr\n",
    "\n",
    "\n",
    "    def solve(self, input:list[int]):\n",
    "        print(\"= = = = = = = = =\")\n",
    "        print(f\"Input \\t\\t: {input}\")\n",
    "        print(f\"weight \\t\\t: {self.weight}\")\n",
    "        print(f\"Activation\\t: {self.activation}\")\n",
    "        print(f\"Sigma \\t\\t: {self.get_sigma(input)}\")\n",
    "        print()\n",
    "        print(f\"Result \\t\\t: {self.get_result(input=input)}\")\n",
    "        print(\"= = = = = = = = =\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNNN:\n",
    "    def __init__(self, bias:list[list[int]], weight:list[list[int]], activation:list[str], input:list[list[int]]):\n",
    "        self.layers = []\n",
    "        self.input = input\n",
    "        # layer paling awal index 0\n",
    "        i = 0\n",
    "        j = 0\n",
    "        for i in  range(len(activation)):\n",
    "            layer = Layer(bias=bias[i], weight=weight[i], activation=activation[i])\n",
    "            self.add_layer(layer)\n",
    "\n",
    "    def add_layer(self, layer:Layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def resolve(self):\n",
    "        result = []\n",
    "        i = 1\n",
    "        for x in self.input:\n",
    "            print(f\"\\n#### INPUT {i} ####\")\n",
    "            input = x\n",
    "            for layer in self.layers:\n",
    "                idx = self.layers.index(layer)\n",
    "                print(f\"\\n====LAYER {idx}====\")\n",
    "                layer.solve(input)\n",
    "                input = layer.get_result(input)\n",
    "            \n",
    "            result.append(input[0])\n",
    "            i += 1\n",
    "        \n",
    "        print()\n",
    "        print(f\"RESULT ==> {result}\")\n",
    "    \n",
    "    def get_results(self):\n",
    "        result = []\n",
    "        for x in self.input:\n",
    "            input = x\n",
    "            for layer in self.layers:\n",
    "                input = layer.get_result(input)\n",
    "            \n",
    "            result.append(input[0])\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eksekusi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# # # # # # # # # # # # # # # # # # #\n",
      "# Feed Forward Neural Network : XOR #\n",
      "# # # # # # # # # # # # # # # # # # #\n",
      "\n",
      "\n",
      "#### INPUT 1 ####\n",
      "\n",
      "====LAYER 0====\n",
      "= = = = = = = = =\n",
      "Input \t\t: [0, 0]\n",
      "weight \t\t: [[1, 1], [1, 1]]\n",
      "Activation\t: relu\n",
      "Sigma \t\t: [0, -1]\n",
      "\n",
      "Result \t\t: [0, -0.0]\n",
      "= = = = = = = = =\n",
      "\n",
      "====LAYER 1====\n",
      "= = = = = = = = =\n",
      "Input \t\t: [0, -0.0]\n",
      "weight \t\t: [[1], [-2]]\n",
      "Activation\t: linear\n",
      "Sigma \t\t: [0.0]\n",
      "\n",
      "Result \t\t: [0.0]\n",
      "= = = = = = = = =\n",
      "\n",
      "#### INPUT 2 ####\n",
      "\n",
      "====LAYER 0====\n",
      "= = = = = = = = =\n",
      "Input \t\t: [0, 1]\n",
      "weight \t\t: [[1, 1], [1, 1]]\n",
      "Activation\t: relu\n",
      "Sigma \t\t: [1, 0]\n",
      "\n",
      "Result \t\t: [1, 0]\n",
      "= = = = = = = = =\n",
      "\n",
      "====LAYER 1====\n",
      "= = = = = = = = =\n",
      "Input \t\t: [1, 0]\n",
      "weight \t\t: [[1], [-2]]\n",
      "Activation\t: linear\n",
      "Sigma \t\t: [1]\n",
      "\n",
      "Result \t\t: [1]\n",
      "= = = = = = = = =\n",
      "\n",
      "#### INPUT 3 ####\n",
      "\n",
      "====LAYER 0====\n",
      "= = = = = = = = =\n",
      "Input \t\t: [1, 0]\n",
      "weight \t\t: [[1, 1], [1, 1]]\n",
      "Activation\t: relu\n",
      "Sigma \t\t: [1, 0]\n",
      "\n",
      "Result \t\t: [1, 0]\n",
      "= = = = = = = = =\n",
      "\n",
      "====LAYER 1====\n",
      "= = = = = = = = =\n",
      "Input \t\t: [1, 0]\n",
      "weight \t\t: [[1], [-2]]\n",
      "Activation\t: linear\n",
      "Sigma \t\t: [1]\n",
      "\n",
      "Result \t\t: [1]\n",
      "= = = = = = = = =\n",
      "\n",
      "#### INPUT 4 ####\n",
      "\n",
      "====LAYER 0====\n",
      "= = = = = = = = =\n",
      "Input \t\t: [1, 1]\n",
      "weight \t\t: [[1, 1], [1, 1]]\n",
      "Activation\t: relu\n",
      "Sigma \t\t: [2, 1]\n",
      "\n",
      "Result \t\t: [1.0, 1]\n",
      "= = = = = = = = =\n",
      "\n",
      "====LAYER 1====\n",
      "= = = = = = = = =\n",
      "Input \t\t: [1.0, 1]\n",
      "weight \t\t: [[1], [-2]]\n",
      "Activation\t: linear\n",
      "Sigma \t\t: [-1.0]\n",
      "\n",
      "Result \t\t: [-1.0]\n",
      "= = = = = = = = =\n",
      "\n",
      "RESULT ==> [0.0, 1, 1, -1.0]\n",
      "\n",
      "TARGET CLASS\t\t: [0, 1, 1, 0]\n",
      "RESULT CLASS\t\t: [0.0, 1, 1, -1.0]\n",
      "===========================\n",
      "Result: BAD PREDICT\n",
      "NO GOOD\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model relu-linier.gv.pdf'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\"# # # # # # # # # # # # # # # # # # #\")\n",
    "print(\"# Feed Forward Neural Network : XOR #\")\n",
    "print(\"# # # # # # # # # # # # # # # # # # #\\n\")\n",
    "\n",
    "bias, weigth , activation = readModel(\"model relu-linier.txt\")\n",
    "data, target = readData()\n",
    "fnnn = FNNN(bias, weigth, activation, data)\n",
    "result = fnnn.get_results()\n",
    "\n",
    "# print result etc\n",
    "fnnn.resolve()\n",
    "print()\n",
    "print(f\"TARGET CLASS\\t\\t: {target}\")\n",
    "print(f\"RESULT CLASS\\t\\t: {result}\")\n",
    "print(\"===========================\")\n",
    "if(result == target):\n",
    "    print(\"Result: GOOD PREDICT\")\n",
    "    print(\"GOOD\")\n",
    "else:\n",
    "    print(\"Result: BAD PREDICT\")\n",
    "    print(\"NO GOOD\")\n",
    "\n",
    "\n",
    "### VISUALIZATION\n",
    "from graphviz import Digraph\n",
    "\n",
    "dGraph = Digraph(\"FNNN: XOR\", filename=\"model relu-linier.gv\")\n",
    "\n",
    "max = len(fnnn.layers)\n",
    "for layer in fnnn.layers:\n",
    "    idxL = fnnn.layers.index(layer)\n",
    "    edges = layer.getDiGraph(idxL, max)\n",
    "    for ed in edges:\n",
    "        dGraph.edge(ed[0], ed[1], str(ed[2]))\n",
    "\n",
    "dGraph.view()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "87624cbd01e71ab47bd8d90f30cc74e4be12813511688651a34b6aa52844c5e5"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
